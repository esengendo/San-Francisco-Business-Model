name: ğŸš€ SF Business Model - Complete CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly on Sundays at 2 AM UTC for data pipeline
    - cron: '0 2 * * 0'
  workflow_dispatch:
    # Allow manual triggers

env:
  DOCKER_IMAGE: esengendo730/sf-business-model
  REGISTRY: docker.io

jobs:
  test:
    name: ğŸ§ª Code Quality & Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ” Code quality tests
        run: |
          echo "ğŸ§ª Testing Python imports..."
          python -c "
          import streamlit
          import torch
          import pandas as pd
          import numpy as np
          print('âœ… All essential imports successful!')
          "
          
          echo "ğŸ“ Checking new folder structure..."
          [ -d "src/data_collection" ] && echo "âœ… Data collection folder exists"
          [ -d "src/processing" ] && echo "âœ… Processing folder exists"
          [ -d "src/models" ] && echo "âœ… Models folder exists"
          [ -d "src/utils" ] && echo "âœ… Utils folder exists"
          [ -d "app" ] && echo "âœ… App folder exists"

  build-and-deploy:
    name: ğŸ³ Build & Deploy to Docker Hub
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name != 'pull_request'
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ³ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ğŸ”‘ Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: ğŸ·ï¸ Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_IMAGE }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=raw,value=latest,enable={{is_default_branch}}
            type=sha,prefix={{branch}}-

      - name: ğŸ”¨ Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: ğŸ‰ Deployment Summary
        run: |
          echo "ğŸ¯ SF Business Model - Deployment Summary"
          echo "==============================================="
          echo "ğŸ³ Docker Image: ${{ env.DOCKER_IMAGE }}:latest"
          echo "ğŸŒ Docker Hub: https://hub.docker.com/r/${{ env.DOCKER_IMAGE }}"
          echo "ğŸš€ Run Command:"
          echo "   docker run -p 8501:8501 ${{ env.DOCKER_IMAGE }}:latest"
          echo "ğŸ“± Access App: http://localhost:8501"
          echo "==============================================="

  data-pipeline:
    name: ğŸ“Š Run Data Pipeline
    runs-on: ubuntu-latest
    needs: build-and-deploy
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    timeout-minutes: 90
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ”§ Create Environment File
        run: |
          cat > .env.docker << EOF
          FRED_API_KEY=${{ secrets.FRED_API_KEY }}
          CENSUS_API_KEY=${{ secrets.CENSUS_API_KEY }}
          SFGOV_API_TOKEN=${{ secrets.SFGOV_API_TOKEN }}
          PIPELINE_MODE=single_run
          LOG_LEVEL=INFO
          BASE_DIR=/app
          EOF
          
      - name: ğŸš€ Run SF Business Data Pipeline
        run: |
          docker run --rm \
            --env-file .env.docker \
            -v ${{ github.workspace }}/data:/app/data \
            -v ${{ github.workspace }}/results:/app/results \
            -v ${{ github.workspace }}/logs:/app/logs \
            ${{ env.DOCKER_IMAGE }}:latest python src/pipeline_runner.py
            
      - name: ğŸ“Š Upload Pipeline Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sf-business-pipeline-results-${{ github.run_number }}
          path: |
            data/
            results/
            logs/
            pipeline_report_*.json
          retention-days: 30

  validate-pipeline:
    name: âœ… Validate Pipeline Results
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: success()
    
    steps:
      - name: ğŸ“Š Download Pipeline Results
        uses: actions/download-artifact@v4
        with:
          name: sf-business-pipeline-results-${{ github.run_number }}
          
      - name: âœ… Validate Results
        run: |
          echo "ğŸ” Validating pipeline results..."
          
          # Check if key files exist
          if ls pipeline_report_*.json 1> /dev/null 2>&1; then
            echo "âœ… Pipeline report found"
            cat pipeline_report_*.json | head -20
          else
            echo "âŒ Pipeline report missing"
            exit 1
          fi
          
          if [ -d "data" ]; then
            echo "âœ… Data directory created"
            du -sh data/
          else
            echo "âŒ Data directory missing"
            exit 1
          fi
          
          echo "ğŸ‰ All validation checks passed!"